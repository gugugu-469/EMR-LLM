[**English**](./README.md) | [**ä¸­æ–‡**](./README_zh.md)
# EMR-LLM
æœ¬ä»“åº“æ˜¯**EMR-LLM**çš„å®˜æ–¹å®ç°ï¼Œè¯¥æ¨¡å‹æ¥è‡ªè®ºæ–‡**A Large Language Model for Electronic Medical Records**

# ç®€è¦ä»‹ç»

æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸“ä¸ºç”µå­ç—…å†çš„å¤§æ¨¡å‹**EMR-LLM**ï¼Œè¯¥æ¨¡å‹èƒ½å……åˆ†ç†è§£ç”µå­ç—…å†çš„å¤æ‚ç»“æ„ï¼Œä»¥åŠåŒ»ç–—ä¸­é‡è¦çš„ä¸´åºŠæ•°å€¼æ•°æ®ã€‚

## ğŸ¤– æ¨¡å‹

**é¦–å…ˆ**ï¼Œæˆ‘ä»¬æ”¶é›†äº†å¤§é‡çš„é€šç”¨è¯­æ–™ã€åŸºç¡€åŒ»ç–—è¯­æ–™å’Œä¸´åºŠæŒ‡å—è¯­æ–™ä½œä¸ºé¢„è®­ç»ƒæ•°æ®ï¼Œä»¥å¢å¼ºLLMçš„åŒ»å­¦é¢†åŸŸçŸ¥è¯†ã€‚

**å…¶æ¬¡**ï¼Œæˆ‘ä»¬ä»ä¸­å›½ä¸‰ç”²åŒ»é™¢ç‘é‡‘åŒ»é™¢æ”¶é›†äº†75,000ä»½ç”µå­ç—…å†ã€‚åŸºäºè¿™äº›ç”µå­ç—…å†ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸‰ç±»æŒ‡ä»¤ä»»åŠ¡ï¼šç»“æ„ç†è§£ã€æ•°å­—ç†è§£å’Œä¸‹æ¸¸åº”ç”¨ã€‚

**æœ€å**ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§èƒ½åŠ›æå‡å¼çš„æŒ‡ä»¤å¾®è°ƒæ–¹æ³•ï¼Œåˆ©ç”¨è¯¥æ•°æ®é›†å¯¹é¢„å…ˆè®­ç»ƒå¥½çš„ LLM è¿›è¡Œå¾®è°ƒã€‚è¿™ç§æ–¹æ³•æ¨¡ä»¿äººç±»çš„å­¦ä¹ è¿‡ç¨‹ï¼Œè®© LLMs å…ˆå­¦ä¹ ç®€å•çš„ä»»åŠ¡ï¼Œç„¶åé€æ­¥å­¦ä¹ æ›´å¤æ‚çš„ä»»åŠ¡ã€‚

EMR-LLMçš„æ•´ä½“æ¶æ„å¦‚ä¸‹:
<div align="center">
  <img src="assets/framework.jpg" alt="Framework" width="100%">
</div>

# ğŸ”¬ ä¾èµ–

è¦è¿è¡Œæˆ‘ä»¬çš„ä»£ç ï¼Œè¯·å®‰è£…ç›¸å…³è½¯ä»¶åŒ…ã€‚
```
accelerate	  0.27.2
deepspeed	    0.14.2
fire	        0.5.0
flash-attn	  2.5.8
ninja	        1.11.1.1
sentencepiece	0.1.99
torch	        2.2.1
vllm	        0.4.1
peft	        0.10.0
trl	          0.8.1
datasets    	2.17.1	
transformers	4.40.0	
scipy	        1.12.0
tiktoken    	0.6.0	
protobuf	    3.20.3	
pydantic    	2.6.1	
matplotlib	  3.8.3	
sse-starlette	2.0.0	
packaging	    23.2	
pyyaml      	6.0.1
pandas	      1.5.3
numpy	        1.23.4
```

# ğŸš€ å¿«é€Ÿå¼€å§‹

å¦‚æœæ‚¨æƒ³ä¸æˆ‘ä»¬çš„æ„å»ºè¿‡ç¨‹ä¿æŒä¸€è‡´ï¼Œè¯·è¿›å…¥ `/train/LLaMA-Factory/ours-script`ç›®å½•ï¼Œå¹¶æŒ‰ç…§ç›®å½•ä¸­çš„è¯´æ˜è¿›è¡Œæ“ä½œã€‚

## é¢„è®­ç»ƒ
```sh
# å‰å¾€ç›¸å…³ç›®å½•
cd /train/LLaMA-Factory/ours-script/pretrain

# è·å¾—æ•°æ®é›†çš„ç¼“å­˜
bash 1_get_cache.sh

# å¼€å§‹é¢„è®­ç»ƒ
bash 2_start_pretrain.sh
```

## æŒ‡ä»¤å¾®è°ƒ
```sh
# å‰å¾€ç›¸å…³ç›®å½•
cd /train/LLaMA-Factory/ours-script/sft

# è·å¾—stage1åˆ°stage4çš„æ•°æ®é›†ç¼“å­˜
bash 1_chatglm_cache_stage1.sh
bash 1_chatglm_cache_stage2.sh
bash 1_chatglm_cache_stage3.sh
bash 1_chatglm_cache_stage4.sh

# å¼€å§‹è¿­ä»£å¼æŒ‡ä»¤å¾®è°ƒ
bash 2_chatglm_train_stage1_lora.sh
# ä¿®æ”¹é…ç½®
bash /train/LLaMA-Factory/ours-script/export_lora_model.sh
bash 2_chatglm_train_stage2_lora.sh
# ä¿®æ”¹é…ç½®
bash /train/LLaMA-Factory/ours-script/export_lora_model.sh
bash 2_chatglm_train_stage3_lora.sh
# ä¿®æ”¹é…ç½®
bash /train/LLaMA-Factory/ours-script/export_lora_model.sh
bash 2_chatglm_train_stage4_lora.sh
# ä¿®æ”¹é…ç½®
bash /train/LLaMA-Factory/ours-script/export_lora_model.sh
```


# ä»£ç ç»“æ„

`./train`:å­˜æ”¾è®­ç»ƒä»£ç ã€‚

`./evaluate`:å­˜æ”¾è¯„æµ‹ä»£ç ã€‚

`dataset`:å­˜æ”¾æ•°æ®é›†æ ·æœ¬ã€‚

# è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢ [hiyouga](https://github.com/hiyouga/LLaMA-Factory) æä¾›æ¨¡å‹çš„è®­ç»ƒæ¡†æ¶ã€‚

é¡¹ç›®åŸºäº [Chatglm3-6b](https://github.com/THUDM/ChatGLM3)ã€‚

æ„Ÿè°¢æ‰€æœ‰æä¾›å¼€æºæ•°æ®çš„åˆ›ä½œè€…ã€‚